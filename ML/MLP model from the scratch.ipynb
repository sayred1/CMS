{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Layer Perceptron from the scratch\n",
    "\n",
    "Nowadays, multi-Layer neural network has been proved to be a powerful tool in many data science problems. Though many existing packages have provided the interfaces to call this function (e.g. scikit-learn), it would be good to write some toy model by your own. Through this practice, you will gain some experience in software engineering. More importantly, you will understand the underlying mathmatics better and know how to fix the troubles when you run the code from the existing softwares. In the tutorial, we will continue to use the wine data and figure out how to write our own MLP classfier.\n",
    "\n",
    "Let us start with the example in the previous lecture\n",
    "```\n",
    "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
    "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
    "       hidden_layer_sizes=(4, 2), learning_rate='constant',\n",
    "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
    "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
    "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
    "       validation_fraction=0.1, verbose=False, warm_start=False)\n",
    "```\n",
    "<img src=\"img/MLP.jpeg\" style=\"width: 800px;\"/>\n",
    "<center> Figure 1, the MLP model used in this lecture</center>\n",
    "\n",
    "You should be able to understand most of the parameters at the moment. To realize a minimum version of MLP, we can try to implement the following parameters into our model:\n",
    "- hidden_layer_sizes: to make life easier, let us just consider 2 hidden layer models\n",
    "- max_iter: maximum number of iteractions\n",
    "- learning_rate_init: \n",
    "\n",
    "Note that we will completely ignore the terms related to regularization\n",
    "\n",
    "## Back propagation\n",
    "$$\\frac{\\partial L}{\\partial y} = y-Y$$\n",
    "$$\\frac{\\partial y}{\\partial f_3} = $$\n",
    "$$\\frac{\\partial f_3}{\\partial h_2} = $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtain and preprocess the data\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "data=load_wine()\n",
    "x, Y = data.data, data.target # in, out data\n",
    "\n",
    "# scale data\n",
    "scaler = StandardScaler()  \n",
    "scaler.fit(x)  \n",
    "x0 = scaler.transform(x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "class my_MLPClassifier(object):\n",
    "    \"\"\"\n",
    "    Basic MultiLayer Perceptron (MLP) neural network.\n",
    "    Args:\n",
    "    hidden layer: []\n",
    "    max_iterations: []\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden, iterations, learning_rate, decay_rate, activation, loss):\n",
    "        \"\"\"\n",
    "        :param hidden: number of hidden neurons\n",
    "        :param iterations: how many epochs\n",
    "        :param learning_rate: initial learning rate\n",
    "        \"\"\"\n",
    "        # initialize input parameters\n",
    "        self.iterations = iterations\n",
    "        self.learning_rate = learning_rate\n",
    "        self.decay_rate = decay_rate\n",
    "        self.n_hid1, self.n_hid2 = hidden[0], hidden[1]\n",
    "        self.activation_method = activation\n",
    "        self.loss_method= loss\n",
    "        \n",
    "    def fit(self, input, target):      \n",
    "        \"\"\"\n",
    "        input: 2D array, N_sample * N_attributes\n",
    "        output: 1D array, N_sample * 1\n",
    "        \"\"\"\n",
    "        # Initialize the weights and bias according to the input/target data\n",
    "        dim_in, dim_out = input.shape[1], 1\n",
    "        self.w1 = np.random.randn(dim_in, self.n_hid1) # [13,4] -- 52 weights \n",
    "        self.w2 = np.random.randn(self.n_hid1, self.n_hid2) # [4,4] -- 16 weights\n",
    "        self.w3 = np.random.randn(self.n_hid2, dim_out) # [4,1] -- 4 weights\n",
    "        self.b1 = np.random.randn(1,self.n_hid1) # [1,4] -- 4 biases\n",
    "        self.b2 = np.random.randn(1,self.n_hid2) # [1,4] -- 4 biases\n",
    "        self.b3 = np.random.randn(1,dim_out)  # [1,1] -- 1 bias\n",
    "        loss_hist = [] # track loss for printing\n",
    "        \n",
    "        \"\"\"\n",
    "        training\n",
    "        \"\"\"\n",
    "        \n",
    "        for i in range(self.iterations):\n",
    "            # forward: input --> hidden layer 1 -- hidden layer 2 -- output\n",
    "            (h1, h2, y) = self.forward(input,self.w1,self.w2,self.w3,self.b1,self.b2,self.b3)\n",
    "            \n",
    "            # evaluate and print the loss function\n",
    "            loss = self.loss(y, target)\n",
    "            loss_hist.append(loss)\n",
    "            \n",
    "            # backprop: output --> hidden layer 2 --> hidden layer 1 --> input\n",
    "            \"\"\"\n",
    "            deltas are the derivatives of the inputs and outputs of the nodes which are used to find the gradients\n",
    "            of the parameters with respect to the cost: gradw & gradb.\n",
    "            \n",
    "            after finding gradw and gradb, the weights and biases are updated.\n",
    "            \"\"\"\n",
    "            \n",
    "            delta3 = self.grad_loss(y, target) * self.grad_activation(y) \n",
    "            gradw3 = np.dot(delta3, h2)\n",
    "            gradb3 = np.sum(delta3)\n",
    "\n",
    "            delta2 = (np.transpose(np.dot(self.w3,np.transpose(np.vstack(delta3)))) * \n",
    "                      self.grad_activation(h2))\n",
    "            gradw2 = np.dot(np.transpose(delta2),h1)\n",
    "            gradb2 = np.sum(delta2)\n",
    "            \n",
    "            delta = (np.transpose(np.dot(self.w2,np.transpose(np.vstack(delta2)))) * \n",
    "                     self.grad_activation(h1))\n",
    "            gradw = np.transpose(np.dot(np.transpose(delta),input))\n",
    "            gradb = np.sum(delta)\n",
    "            \n",
    "            # updating the weight\n",
    "            w3, b3, w2, b2, w1, b1 = self.w3.flatten(), self.b3, self.w2, self.b2, self.w1, self.b1\n",
    "            learning_rate = self.learning_rate * (self.decay_rate**i)\n",
    "            w3 -= learning_rate*gradw3\n",
    "            b3 -= learning_rate*gradb3\n",
    "            w2 -= learning_rate*gradw2\n",
    "            b2 -= learning_rate*gradb2\n",
    "            w1 -= learning_rate*gradw\n",
    "            b1 -= learning_rate*gradb\n",
    "        self.weights = (w3, w2, w1)\n",
    "        self.bias = (b3, b2, b1)\n",
    "        print('loss is {:4f} after {:4d} iterations'.format(loss, self.iterations))\n",
    "        plt.title('training curve')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel('loss')\n",
    "        plt.plot(np.arange(0,self.iterations),loss_hist)\n",
    "  \n",
    "    def loss(self, y, target):\n",
    "        if self.loss_method=='mse':\n",
    "            return 0.5*np.sum(np.power(y-target,2))/y.shape[0]\n",
    "        elif self.loss.method=='log_loss':\n",
    "            pass\n",
    "        else:\n",
    "            raise Notimplementederror\n",
    "    \n",
    "    def grad_loss(self, y, target):\n",
    "        if self.loss_method=='mse':\n",
    "            return y-target\n",
    "        elif self.loss_method=='log_loss':\n",
    "            pass\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "    def activation(self, x):\n",
    "        return 1./(1+np.exp(-x))\n",
    "    \n",
    "    def grad_activation(self, x):\n",
    "        if self.activation_method=='sigmoid':\n",
    "            return self.activation(x)*(1-self.activation(x))\n",
    "        elif self.activation_method=='log_loss':\n",
    "            pass\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "            \n",
    "    def forward(self, X, w1, w2, w3, b1, b2, b3):\n",
    "        h1 = self.activation(np.dot(X,w1)+b1)\n",
    "        h2 = self.activation(np.dot(h1,w2)+b2)\n",
    "        y = self.activation(np.dot(h2,w3)+b3)\n",
    "        return (h1, h2, y.flatten())\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        return predictions after training algorithm\n",
    "        \"\"\"\n",
    "        (h1, h2, y) = self.forward(X)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is 0.302665 after 1000 iterations\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### mlp parameters\n",
    "hidd_layers = [4,4]\n",
    "max_iter = 1000\n",
    "lr = 0.001\n",
    "decay = 0.99\n",
    "activation = 'sigmoid'\n",
    "loss = 'mse'\n",
    "\n",
    "my_mlp = my_MLPClassifier(hidd_layers,max_iter,lr,decay,activation,loss)\n",
    "my_mlp.fit(x0, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
